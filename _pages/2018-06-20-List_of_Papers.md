---
layout: single
classes: wide
permalink: /work_OSU/SENSE_Lab_discuss/
title: "SENSE-Lab Paper Discussion"
author_profile: false
header:
  image: "images/senselab1.png"
excerpt: "List of Papers"
---
## List of Important papers

## Year 2018

### Discussed Papers
1. Xin, B., Wang, Y., Gao, W., Wipf, D. and Wang, B., 2016. Maximal sparsity with deep networks?. In Advances in Neural Information Processing Systems (pp. 4340-4348). Goto Meeting 1 page [here](/Meeting_1_SU18/).
2. Patel, A.B., Nguyen, M.T. and Baraniuk, R., 2016. A probabilistic framework for deep learning. In Advances in neural information processing systems (pp. 2558-2566).  Goto Meeting 2 page [here](/Meeting_2_SU18/).
3. Johnson, M.J., Duvenaud, D., Wiltschko, A.B., Datta, S.R. and Adams, R.P., 2016. Structured VAEs: Composing probabilistic graphical models and variational autoencoders. arXiv preprint arXiv:1603.06277, 2, p.2016. Goto Meeting 3 page [here](/Meeting_3_SU18/).
4. Giryes, R., Eldar, Y.C., Bronstein, A.M. and Sapiro, G., 2016. Tradeoffs between convergence speed and reconstruction accuracy in inverse problems. arXiv preprint arXiv:1605.09232. Goto Meeting 4 page [here](/Meeting_4_SU18/).
5. Chang, J.H.R., Li, C.L., Poczos, B., Kumar, B.V. and Sankaranarayanan, A.C., 2017, March. One Network to Solve Them All-Solving Linear Inverse Problems using Deep Projection Models. In ICCV (pp. 5889-5898). Goto Meeting 5 page [here](/Meeting_5_SU18/).
6. Achille, A. and Soatto, S., 2017. Emergence of invariance and disentangling in deep representations. arXiv preprint arXiv:1706.01350. Goto Meeting 6 page [here](/Meeting_6_SU18/).
7. Blundell, C., Cornebise, J., Kavukcuoglu, K. and Wierstra, D., 2015. Weight uncertainty in neural networks. arXiv preprint arXiv:1505.05424. Goto Meeting 7 page [here](/Meeting_7_SU18/).


### Other Relevant Papers
1. Mousavi, A. and Baraniuk, R.G., 2017, March. Learning to invert: Signal recovery via deep convolutional networks. In Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on (pp. 2272-2276). IEEE [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7952561)
2. Samuel, N., Diskin, T. and Wiesel, A., 2017. Deep MIMO detection. arXiv preprint arXiv:1706.01151. [link](https://arxiv.org/pdf/1706.01151.pdf)
3. Oktay, O., Ferrante, E., Kamnitsas, K., Heinrich, M., Bai, W., Caballero, J., Cook, S.A., de Marvao, A., Dawes, T., O‘Regan, D.P. and Kainz, B., 2018. Anatomically constrained neural networks (ACNNs): application to cardiac image enhancement and segmentation. IEEE transactions on medical imaging, 37(2), pp.384-395. [link](https://arxiv.org/pdf/1705.08302.pdf)
4. Schlemper, J., Caballero, J., Hajnal, J.V., Price, A.N. and Rueckert, D., 2018. A deep cascade of convolutional neural networks for dynamic MR image reconstruction. IEEE transactions on Medical Imaging, 37(2), pp.491-503. [link](https://arxiv.org/pdf/1704.02422.pdf)
5. He, H., Xin, B., Ikehata, S. and Wipf, D., 2017. From Bayesian Sparsity to Gated Recurrent Nets. In Advances in Neural Information Processing Systems (pp. 5560-5570). - [link](http://papers.nips.cc/paper/7139-from-bayesian-sparsity-to-gated-recurrent-nets.pdf)
6. Azizan, N. and Hassibi, B., 2018. Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization. arXiv preprint arXiv:1806.00952.  - [link](https://arxiv.org/abs/1806.00952)
7. Jin, K.H., McCann, M.T., Froustey, E. and Unser, M., 2017. Deep convolutional neural network for inverse problems in imaging. IEEE Transactions on Image Processing, 26(9), pp.4509-4522.  - [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7949028&tag=1)
8. Ye, J.C., Han, Y. and Cha, E., 2018. Deep convolutional framelets: A general deep learning framework for inverse problems. SIAM Journal on Imaging Sciences, 11(2), pp.991-1048. - [link](https://arxiv.org/pdf/1707.00372.pdf)
9. Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A.C. and Bengio, Y., 2015. A recurrent latent variable model for sequential data. In Advances in neural information processing systems (pp. 2980-2988).  - [link](https://arxiv.org/pdf/1506.02216.pdf)
10. Fraccaro, M., Sønderby, S.K., Paquet, U. and Winther, O., 2016. Sequential neural models with stochastic layers. In Advances in neural information processing systems (pp. 2199-2207).  - [link](http://papers.nips.cc/paper/6039-sequential-neural-models-with-stochastic-layers)
11. Kalchbrenner, N., Espeholt, L., Simonyan, K., Oord, A.V.D., Graves, A. and Kavukcuoglu, K., 2016. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099.  - [link](https://arxiv.org/pdf/1610.10099.pdf)


## Year 2019

### Discussed Papers

1. Wu, Y., Rosca, M. and Lillicrap, T., 2019. Deep Compressed Sensing. arXiv preprint arXiv:1905.06723. -[link](https://arxiv.org/pdf/1905.06723.pdf)

### Other Relevant Papers

1. Grover, A. and Ermon, S., 2018. Uncertainty autoencoders: Learning compressed representations via variational information maximization. arXiv preprint arXiv:1812.10539. -[link](https://arxiv.org/pdf/1812.10539.pdf)
2. Zhang, Z., Wu, Y., Gan, C. and Zhu, Q., 2019. The optimally designed autoencoder network for compressed sensing. EURASIP Journal on Image and Video Processing, 2019(1), p.56. -[link](https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-019-0460-5)
3. Finn, C., Abbeel, P. and Levine, S., 2017, August. Model-agnostic meta-learning for fast adaptation of deep networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70 (pp. 1126-1135). JMLR. org. -[link](https://arxiv.org/pdf/1703.03400.pdf)
4. Li, Y. and Strohmer, T., 2019. What Happens on the Edge, Stays on the Edge: Toward Compressive Deep Learning. arXiv preprint arXiv:1909.01539. -[link](https://arxiv.org/pdf/1909.01539.pdf)


Visit Lab's web-site [here](http://www2.ece.ohio-state.edu/~ertine/)
