---
layout: single
classes: wide
permalink: /work_OSU/SENSE_Lab_discuss/
title: "SENSE-Lab Paper Discussion"
author_profile: false
header:
  image: "images/senselab1.png"
excerpt: "List of Papers"
---
## List of Important papers



## Information theoretic principles behind deep-learning
1. Achille, A. and Soatto, S., 2017. Emergence of invariance and disentangling in deep representations. arXiv preprint arXiv:1706.01350. Goto Meeting 6 page [here](/Meeting_6_SU18/).
2. Shwartz-Ziv, R. and Tishby, N., 2017. Opening the black box of deep neural networks via information. arXiv preprint arXiv:1703.00810.
3. Achille, A., Lam, M., Tewari, R., Ravichandran, A., Maji, S., Fowlkes, C., Soatto, S. and Perona, P., 2019. Task2Vec: Task Embedding for Meta-Learning. arXiv preprint arXiv:1902.03545.
4. Achille, A. and Soatto, S., 2018. Information dropout: Learning optimal representations through noisy computation. IEEE transactions on pattern analysis and machine intelligence, 40(12), pp.2897-2905.

## Synthetic aperture radar ATR
1. Zhong, Y. and Ettinger, G., 2017. Enlightening deep neural networks with knowledge of confounding factors. In Proceedings of the IEEE International Conference on Computer Vision (pp. 1077-1086).
2. Chen, S., Wang, H., Xu, F. and Jin, Y.Q., 2016. Target classification using the deep convolutional networks for SAR images. IEEE Transactions on Geoscience and Remote Sensing, 54(8), pp.4806-4817.
3. Ding, J., Chen, B., Liu, H. and Huang, M., 2016. Convolutional neural network with data augmentation for SAR target recognition. IEEE Geoscience and remote sensing letters, 13(3), pp.364-368.
4. Huang, Z., Pan, Z. and Lei, B., 2017. Transfer learning with deep convolutional neural network for SAR target classification with limited labeled data. Remote Sensing, 9(9), p.907.
5. Gao, F., Yang, Y., Wang, J., Sun, J., Yang, E. and Zhou, H., 2018. A deep convolutional generative adversarial networks (DCGANs)-based semi-supervised method for object recognition in synthetic aperture radar (SAR) images. Remote Sensing, 10(6), p.846.
6. Alver, M.B., Atito, S. and Çetin, M., 2018, October. SAR ATR in the phase history domain using deep convolutional neural networks. In Image and Signal Processing for Remote Sensing XXIV (Vol. 10789, p. 1078913). International Society for Optics and Photonics.
7. Wang, P. and Patel, V.M., 2018, April. Generating high quality visible images from SAR images using CNNs. In 2018 IEEE Radar Conference (RadarConf18) (pp. 0570-0575). IEEE.
8. SAR Target Recognition via Supervised Discriminative Dictionary Learning and Sparse Representation of the SAR-HOG Feature

## Machine Learning on PPG data
1. Zhang, Z., Pi, Z. and Liu, B., 2014. TROIKA: A general framework for heart rate monitoring using wrist-type photoplethysmographic signals during intensive physical exercise. IEEE Transactions on biomedical engineering, 62(2), pp.522-531.
2. Zhang, Y., Song, S., Vullings, R., Biswas, D., Simões-Capela, N., Van Helleputte, N., Van Hoof, C. and Groenendaal, W., 2019. Motion artifact reduction for wrist-worn photoplethysmograph sensors based on different wavelengths. Sensors, 19(3), p.673.
3. Zhang, Z., 2015. Photoplethysmography-based heart rate monitoring in physical activities via joint sparse spectrum reconstruction. IEEE transactions on biomedical engineering, 62(8), pp.1902-1910.
4. Zhu, L., Kan, C., Du, Y. and Du, D., 2018. Heart rate monitoring during physical exercise from photoplethysmography using neural network. IEEE sensors letters, 3(1), pp.1-4.

## Solving inverse problems using Neural nets
1. Xin, B., Wang, Y., Gao, W., Wipf, D. and Wang, B., 2016. Maximal sparsity with deep networks?. In Advances in Neural Information Processing Systems (pp. 4340-4348). Goto Meeting 1 page [here](/Meeting_1_SU18/).
2. Patel, A.B., Nguyen, M.T. and Baraniuk, R., 2016. A probabilistic framework for deep learning. In Advances in neural information processing systems (pp. 2558-2566).  Goto Meeting 2 page [here](/Meeting_2_SU18/).
3. Mousavi, A. and Baraniuk, R.G., 2017, March. Learning to invert: Signal recovery via deep convolutional networks. In Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on (pp. 2272-2276). IEEE [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7952561)
4. He, H., Xin, B., Ikehata, S. and Wipf, D., 2017. From Bayesian Sparsity to Gated Recurrent Nets. In Advances in Neural Information Processing Systems (pp. 5560-5570). - [link](http://papers.nips.cc/paper/7139-from-bayesian-sparsity-to-gated-recurrent-nets.pdf)
5. Ye, J.C., Han, Y. and Cha, E., 2018. Deep convolutional framelets: A general deep learning framework for inverse problems. SIAM Journal on Imaging Sciences, 11(2), pp.991-1048. - [link](https://arxiv.org/pdf/1707.00372.pdf)
6. Giryes, R., Eldar, Y.C., Bronstein, A.M. and Sapiro, G., 2016. Tradeoffs between convergence speed and reconstruction accuracy in inverse problems. arXiv preprint arXiv:1605.09232. Goto Meeting 4 page [here](/Meeting_4_SU18/).
7. Chang, J.H.R., Li, C.L., Poczos, B., Kumar, B.V. and Sankaranarayanan, A.C., 2017, March. One Network to Solve Them All-Solving Linear Inverse Problems using Deep Projection Models. In ICCV (pp. 5889-5898). Goto Meeting 5 page [here](/Meeting_5_SU18/).

## Variational Inference in Deep Learning
1. Blundell, C., Cornebise, J., Kavukcuoglu, K. and Wierstra, D., 2015. Weight uncertainty in neural networks. arXiv preprint arXiv:1505.05424. Goto Meeting 7 page [here](/Meeting_7_SU18/).
2. Johnson, M.J., Duvenaud, D., Wiltschko, A.B., Datta, S.R. and Adams, R.P., 2016. Structured VAEs: Composing probabilistic graphical models and variational autoencoders. arXiv preprint arXiv:1603.06277, 2, p.2016. Goto Meeting 3 page [here](/Meeting_3_SU18/).
3. Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A.C. and Bengio, Y., 2015. A recurrent latent variable model for sequential data. In Advances in neural information processing systems (pp. 2980-2988).  - [link](https://arxiv.org/pdf/1506.02216.pdf)
4. Fraccaro, M., Sønderby, S.K., Paquet, U. and Winther, O., 2016. Sequential neural models with stochastic layers. In Advances in neural information processing systems (pp. 2199-2207).  - [link](http://papers.nips.cc/paper/6039-sequential-neural-models-with-stochastic-layers)

## Solving Imaging problems with neural nets
1. Oktay, O., Ferrante, E., Kamnitsas, K., Heinrich, M., Bai, W., Caballero, J., Cook, S.A., de Marvao, A., Dawes, T., O‘Regan, D.P. and Kainz, B., 2018. Anatomically constrained neural networks (ACNNs): application to cardiac image enhancement and segmentation. IEEE transactions on medical imaging, 37(2), pp.384-395. [link](https://arxiv.org/pdf/1705.08302.pdf)
2. Jin, K.H., McCann, M.T., Froustey, E. and Unser, M., 2017. Deep convolutional neural network for inverse problems in imaging. IEEE Transactions on Image Processing, 26(9), pp.4509-4522.  - [link](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7949028&tag=1)
3. Schlemper, J., Caballero, J., Hajnal, J.V., Price, A.N. and Rueckert, D., 2018. A deep cascade of convolutional neural networks for dynamic MR image reconstruction. IEEE transactions on Medical Imaging, 37(2), pp.491-503. [link](https://arxiv.org/pdf/1704.02422.pdf)

## Classification with compressive samples
1. Wu, Y., Rosca, M. and Lillicrap, T., 2019. Deep Compressed Sensing. arXiv preprint arXiv:1905.06723. -[link](https://arxiv.org/pdf/1905.06723.pdf)
2. Li, Y. and Strohmer, T., 2019. What Happens on the Edge, Stays on the Edge: Toward Compressive Deep Learning. arXiv preprint arXiv:1909.01539. -[link](https://arxiv.org/pdf/1909.01539.pdf)
3. Grover, A. and Ermon, S., 2018. Uncertainty autoencoders: Learning compressed representations via variational information maximization. arXiv preprint arXiv:1812.10539. -[link](https://arxiv.org/pdf/1812.10539.pdf)
4. Zhang, Z., Wu, Y., Gan, C. and Zhu, Q., 2019. The optimally designed autoencoder network for compressed sensing. EURASIP Journal on Image and Video Processing, 2019(1), p.56. -[link](https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-019-0460-5)
5. Finn, C., Abbeel, P. and Levine, S., 2017, August. Model-agnostic meta-learning for fast adaptation of deep networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70 (pp. 1126-1135). JMLR. org. -[link](https://arxiv.org/pdf/1703.03400.pdf)


## Understanding optimization in non-convex settings
1. Azizan, N. and Hassibi, B., 2018. Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization. arXiv preprint arXiv:1806.00952.  - [link](https://arxiv.org/abs/1806.00952)

## Other Relevant Papers
1. Samuel, N., Diskin, T. and Wiesel, A., 2017. Deep MIMO detection. arXiv preprint arXiv:1706.01151. [link](https://arxiv.org/pdf/1706.01151.pdf)
2. Kalchbrenner, N., Espeholt, L., Simonyan, K., Oord, A.V.D., Graves, A. and Kavukcuoglu, K., 2016. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099.  - [link](https://arxiv.org/pdf/1610.10099.pdf)

Visit Lab's web-site [here](http://www2.ece.ohio-state.edu/~ertine/)
